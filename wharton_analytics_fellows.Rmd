
---
title: ""
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```


<style type="text/css">
.title {
  display: none;
}

#getting-started img {
  margin-right: 1px;
}

</style>

<div class="row" style="padding-top: 30px;">
<div class="col-sm-6">

# Overview



<a href = "https://wca.wharton.upenn.edu/students/analytics-fellows/" target = "_blank"> Wharton Analytics Fellows </a>is a fellowship program that unites graduate and undergraduate students across schools at Penn to consult with companies on analytics solutions for business practice. 



# YouTube


Product teams often hope to better curate content creation based on previously popular products. Here, I build an
unsupervised learning algorithm to find trends in <a href = "https://www.kaggle.com/datasnaek/youtube-new/" target = "_blank"> a large dataset </a> of YouTube videos. Clustering results inform the sales team on pricing strategies for ads, and the product team on content needs. 


### Technical

Data cleaning: tidyverse </br>
Clustering: factoextra

### Sample

Sample code and charts below. See <a href = "https://github.com/katjanewilson/YouTube" target = "_blank"> GitHub repo </a> for full code and analysis.

```{r echo=TRUE}
library(tidyverse)
load(file = "data/data1.Rdata")
df <- data %>%
  select(average_comments, average_dislikes,
         average_likes, average_views)

#scale the data
df<- scale(df)
library(factoextra)
distance <- get_dist(df)
plot<- fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
plot

#to determine the optimal number of clusters
set.seed(123)

#function to compute total within-cluster sum of square 
wss <- function(k) {
  kmeans(df, k, nstart = 10 )$tot.withinss
}
k.values <- 1:15

# extract wss
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters",
     ylab="Total Sum of Squares")

k2 <- kmeans(df[,(1:3)], centers = 3, nstart = 25)

df %>%
  as_tibble() %>%
  mutate(cluster = k2$cluster,
         names = row.names(data)) %>%
  ggplot(aes(average_views, average_comments, color = factor(cluster), label = names)) +
  geom_text(alpha = .7) +
  ggtitle("Clusters") +
  ylab("Average Comments" )+
  xlab("Average Views") +
  theme(legend.position = "none") +
  theme_minimal()
```




# MLB


Looking for any edge above the competitor, MLB teams have now turned to psychometric and biometric data in addition to performance data. In this project, we worked with a Major League Baseball team to analyze how players' psychological data influences their performance statistics. 


### Technical

Data cleaning: tidyverse </br>
Text Mining: tm package, tidytext
Clustering: hclust, PCA

### Sample
